{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fa2f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3270d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "qdrant_key = os.getenv(\"QDRANT_KEY\")\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f37b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(docs_list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=50,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    return doc_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c94d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_doc = HuggingFaceDatasetLoader(\"m-ric/huggingface_doc\",\"text\")\n",
    "transformers_doc = HuggingFaceDatasetLoader(\"m-ric/transformers_documentation_en\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea830cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_docs=50\n",
    "hf_splits = preprocess_dataset(hugging_face_doc.load()[:number_of_docs])\n",
    "transformer_splits = preprocess_dataset(transformers_doc.load()[:number_of_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ec0a8",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b573f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "def create_retriever(collection_name, doc_splits):\n",
    "    vectorstore = QdrantVectorStore.from_documents(\n",
    "        doc_splits,\n",
    "        HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "        url=qdrant_url,\n",
    "        api_key=qdrant_key,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "hf_retriever = create_retriever(\"huggingface_doc\", hf_splits)\n",
    "transformer_retriever = create_retriever(\"transformers_doc\", transformer_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be661718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "hf_retriever_tool = create_retriever_tool(\n",
    "    hf_retriever,\n",
    "    \"retriever_hugging_face_documentation\",\n",
    "    \"Search and return information about hugging face documentation, it includes the guide and Python code.\",\n",
    ")\n",
    "\n",
    "transformer_retriever_tool = create_retriever_tool(\n",
    "    transformer_retriever,\n",
    "    \"retriever_transformer\",\n",
    "    \"Search and return information specifically about transformers library\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063f64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tools = [hf_retriever_tool, transformer_retriever_tool, TavilySearch(max_results=1)]\n",
    "\n",
    "inference_server_url = \"http://localhost:8000/v1\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "    openai_api_key=\"binhphap5\",\n",
    "    openai_api_base=inference_server_url,\n",
    "    max_tokens=1024,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    ").bind_tools(tools=tools, tool_choice=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fae3d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(\n",
    "    state: State\n",
    "):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Set the entrypoint as agent. This means that this node is the first one called \n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use 'agent'.\n",
    "    # This means these are the edges taken after the 'agent' node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from 'tools' to 'agent'.\n",
    "# This means that after 'tools' is called, 'agent' node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Now we can compile and visualize our graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80b120aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f7065062290>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18906ef",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f280297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "system_prompt = SystemMessage(\n",
    "    \"\"\"\n",
    "    You are a reasoning agent designed to solve problems by selecting and using tools when needed.\n",
    "\n",
    "    You have access to the following tools:\n",
    "    - retriever_transformer: Search and return information specifically about transformers library.\n",
    "    - retriever_hugging_face_documentation: Search and return information about hugging face documentation, it includes the guide and Python code.\n",
    "    - tavily_search: Search and return information about current events.\n",
    "\n",
    "    Your job is to:\n",
    "    1. Think step-by-step about how to solve the user's request.\n",
    "    2. If a tool is needed, decide **which tool** is best and provide the **correct arguments** for it.\n",
    "\n",
    "    The system will automatically call the tool for you — you do not need to write code or JSON.\n",
    "    Just make sure to:\n",
    "    - Select the correct tool.\n",
    "    - Provide the correct arguments (matching the function schema).\n",
    "    - Only request one tool at a time.\n",
    "    - After receiving the result, continue provide your thought about the previous result.\n",
    "\n",
    "    Once you have enough information, respond with:\n",
    "\n",
    "    Final Answer: <your final answer here>\n",
    "\n",
    "    Be precise, concise, and always follow this reasoning loop:\n",
    "    Thought → [Tool Call if needed] → Observation → Repeat or Final Answer.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0febd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input: str, is_thinking: bool = False):\n",
    "    if not is_thinking:\n",
    "        user_input = user_input + \" /no_think\"\n",
    "    for event in graph.stream({\"messages\": [{\"type\": \"system\", \"content\": system_prompt.content}, {\"type\": \"human\", \"content\": user_input}]}, stream_mode=\"values\"):\n",
    "        last_message = event[\"messages\"][-1]\n",
    "        last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ad76d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Wha is PhoBERT ? Who is behind that model, is there any variant of PhoBERT ? /no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Thought: I need to find information about PhoBERT, including who developed it and if there are any variants. I will use the retriever_hugging_face_documentation tool to search for this information.\n",
      "Tool Calls:\n",
      "  retriever_hugging_face_documentation (chatcmpl-tool-2c00cccc277a4f08abb9af56d4b49fab)\n",
      " Call ID: chatcmpl-tool-2c00cccc277a4f08abb9af56d4b49fab\n",
      "  Args:\n",
      "    query: PhoBERT model, who is behind it, variants of PhoBERT\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retriever_hugging_face_documentation\n",
      "\n",
      "by Yuanzhi Li, S\\u00e9bastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar and Yin Tat Lee.\\n1. **[PhoBERT](https://huggingface.co/docs/transformers/model_doc/phobert)** (from VinAI Research) released with the paper [PhoBERT: Pre-trained language models for Vietnamese](https://www.aclweb.org/anthology/2020.findings-emnlp.92/) by Dat Quoc Nguyen and Anh Tuan Nguyen.\\n1. **[Pix2Struct](https://huggingface.co/docs/transformers/model_doc/pix2struct)** (from Google) released with the paper [Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding](https://arxiv.org/abs/2210.03347) by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.\\n1. **[PLBart](https://huggingface.co/docs/transformers/model_doc/plbart)** (from UCLA NLP) released with the paper [Unified Pre-training for Program Understanding and Generation](https://arxiv.org/abs/2103.06333) by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.\\n1. **[PoolFormer](https://huggingface.co/docs/transformers/model_doc/poolformer)** (from Sea AI Labs) released with the paper [MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.\\n1. **[Pop2Piano](https://huggingface.co/docs/transformers/model_doc/pop2piano)** released with the paper [Pop2Piano : Pop Audio-based Piano Cover Generation](https://arxiv.org/abs/2211.00895) by Jongho Choi and Kyogu Lee.\\n1. **[ProphetNet](https://huggingface.co/docs/transformers/model_doc/prophetnet)** (from Microsoft Research) released with the paper [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.\\n1. **[PVT](https://huggingface.co/docs/transformers/model_doc/pvt)** (from Nanjing\n",
      "\n",
      "(from HuggingFace), released together with the paper [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation) and a German version of DistilBERT.\\n1. **[DiT](https://huggingface.co/docs/transformers/model_doc/dit)** (from Microsoft Research) released with the paper [DiT: Self-supervised Pre-training for Document Image Transformer](https://arxiv.org/abs/2203.02378) by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.\\n1. **[Donut](https://huggingface.co/docs/transformers/model_doc/donut)** (from NAVER), released together with the paper [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664) by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.\\n1. **[DPR](https://huggingface.co/docs/transformers/model_doc/dpr)** (from Facebook) released with the paper [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906) by Vladimir Karpukhin, Barlas O\\u011fuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.\\n1. **[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)** (from Intel Labs) released with the paper [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413) by Ren\\u00e9 Ranftl, Alexey Bochkovskiy, Vladlen Koltun.\\n1. **[EfficientFormer](https://huggingface.co/docs/transformers/model_doc/efficientformer)** (from Snap Research) released with the paper [EfficientFormer: Vision Transformers at MobileNetSpeed](https://arxiv.org/abs/2206.01191) by Yanyu\n",
      "\n",
      "Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei\\n1. **[FLAN-UL2](https://huggingface.co/docs/transformers/model_doc/flan-ul2)** (from Google AI) released in the repository [google-research/t5x](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-ul2-checkpoints) by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei\\n1. **[FlauBERT](https://huggingface.co/docs/transformers/model_doc/flaubert)** (from CNRS) released with the paper [FlauBERT: Unsupervised Language Model Pre-training for French](https://arxiv.org/abs/1912.05372) by Hang Le, Lo\\u00efc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno\\u00eet Crabb\\u00e9, Laurent Besacier, Didier Schwab.\\n1. **[FLAVA](https://huggingface.co/docs/transformers/model_doc/flava)** (from Facebook AI) released with the paper [FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/abs/2112.04482) by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.\\n1. **[FNet](https://huggingface.co/docs/transformers/model_doc/fnet)** (from Google Research) released with the paper [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824) by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.\\n1. **[FocalNet](https://huggingface.co/docs/transformers/model_doc/focalnet)** (from Microsoft Research) released with the paper [Focal Modulation\n",
      "\n",
      "Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.\\n1. **[Longformer](https://huggingface.co/docs/transformers/model_doc/longformer)** (from AllenAI) released with the paper [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) by Iz Beltagy, Matthew E. Peters, Arman Cohan.\\n1. **[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)** (from Google AI) released with the paper [LongT5: Efficient Text-To-Text Transformer for Long Sequences](https://arxiv.org/abs/2112.07916) by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.\\n1. **[LUKE](https://huggingface.co/docs/transformers/model_doc/luke)** (from Studio Ousia) released with the paper [LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention](https://arxiv.org/abs/2010.01057) by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.\\n1. **[LXMERT](https://huggingface.co/docs/transformers/model_doc/lxmert)** (from UNC Chapel Hill) released with the paper [LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.\\n1. **[M-CTC-T](https://huggingface.co/docs/transformers/model_doc/mctct)** (from Facebook) released with the paper\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Thought: The information retrieved mentions that PhoBERT is a pre-trained language model for Vietnamese developed by VinAI Research, as described in the paper \"PhoBERT: Pre-trained language models for Vietnamese\" by Dat Quoc Nguyen and Anh Tuan Nguyen. However, it does not mention any variants of PhoBERT. I will use the retriever_transformer tool to search for more detailed information about PhoBERT and its variants.\n",
      "Tool Calls:\n",
      "  retriever_transformer (chatcmpl-tool-df2c1bbb0170486da953bff466d19bd0)\n",
      " Call ID: chatcmpl-tool-df2c1bbb0170486da953bff466d19bd0\n",
      "  Args:\n",
      "    query: PhoBERT model, variants of PhoBERT\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retriever_transformer\n",
      "\n",
      "|       \\u2705        |         \\u2705         |      \\u2705      |\\n\\n|                     [PEGASUS-X](model_doc/pegasus_x)                     |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                     [Perceiver](model_doc/perceiver)                     |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                     [Persimmon](model_doc/persimmon)                     |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                           [Phi](model_doc/phi)                           |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                       [PhoBERT](model_doc/phobert)                       |       \\u2705        |         \\u2705         |      \\u2705      |\\n\\n|                    [Pix2Struct](model_doc/pix2struct)\n",
      "\n",
      "[Longformer](model_doc/longformer)                    |       \\u2705        |         \\u2705         |      \\u274c      |\\n\\n|                        [LongT5](model_doc/longt5)                        |       \\u2705        |         \\u274c         |      \\u2705      |\\n\\n|                          [LUKE](model_doc/luke)                          |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                        [LXMERT](model_doc/lxmert)                        |       \\u2705        |         \\u2705         |      \\u274c      |\\n\\n|                        [M-CTC-T](model_doc/mctct)                        |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                       [M2M100](model_doc/m2m_100)                        |       \\u2705        |         \\u274c         |\n",
      "\n",
      "|\\n\\n|                    [Pix2Struct](model_doc/pix2struct)                    |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                        [PLBart](model_doc/plbart)                        |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                    [PoolFormer](model_doc/poolformer)                    |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                     [Pop2Piano](model_doc/pop2piano)                     |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                    [ProphetNet](model_doc/prophetnet)                    |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                           [PVT](model_doc/pvt)                           |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|\n",
      "\n",
      "|       \\u2705        |         \\u2705         |      \\u274c      |\\n\\n|                        [BLIP-2](model_doc/blip-2)                        |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                         [BLOOM](model_doc/bloom)                         |       \\u2705        |         \\u274c         |      \\u2705      |\\n\\n|                          [BORT](model_doc/bort)                          |       \\u2705        |         \\u2705         |      \\u2705      |\\n\\n|                   [BridgeTower](model_doc/bridgetower)                   |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                          [BROS](model_doc/bros)                          |       \\u2705        |         \\u274c         |      \\u274c      |\\n\\n|                          [ByT5](model_doc/byt5)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Thought: The information retrieved confirms that PhoBERT is a pre-trained language model for Vietnamese developed by VinAI Research. However, there is no mention of any variants of PhoBERT in the provided information. I will use the tavily_search tool to search for more detailed information about PhoBERT and its variants.\n",
      "Tool Calls:\n",
      "  tavily_search (chatcmpl-tool-9b7a0f16b467490bb46cb88c82c8a18e)\n",
      " Call ID: chatcmpl-tool-9b7a0f16b467490bb46cb88c82c8a18e\n",
      "  Args:\n",
      "    query: PhoBERT model, variants of PhoBERT\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"PhoBERT model, variants of PhoBERT\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://huggingface.co/docs/transformers/en/model_doc/phobert\", \"title\": \"PhoBERT - Hugging Face\", \"content\": \"We present PhoBERT with two versions, PhoBERT-base and PhoBERT-large, the first public large-scale monolingual\\nlanguage models pre-trained for Vietnamese. Experimental results show that PhoBERT consistently outperforms the recent\\nbest pre-trained multilingual model XLM-R (Conneau et al., 2020) and improves the state-of-the-art in multiple\\nVietnamese-specific NLP tasks including Part-of-speech tagging, Dependency parsing, Named-entity recognition and\\nNatural language inference.\", \"score\": 0.8266142, \"raw_content\": null}], \"response_time\": 2.27}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Thought: The search result indicates that PhoBERT has two versions: PhoBERT-base and PhoBERT-large. These are the first public large-scale monolingual language models pre-trained for Vietnamese. They outperform the XLM-R model and improve the state-of-the-art in various Vietnamese-specific NLP tasks.\n",
      "\n",
      "Final Answer: PhoBERT is a pre-trained language model for Vietnamese developed by VinAI Research. It has two versions: PhoBERT-base and PhoBERT-large. These models outperform the recent best pre-trained multilingual model XLM-R and improve the state-of-the-art in multiple Vietnamese-specific NLP tasks such as Part-of-speech tagging, Dependency parsing, Named-entity recognition, and Natural language inference.\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"What is PhoBERT ? Who is behind that model, is there any variant of PhoBERT ?\", is_thinking=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
